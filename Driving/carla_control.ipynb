{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all imports\n",
    "import carla #the sim library itself\n",
    "import random #to pick random spawn point\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "\n",
    "\n",
    "# for math and calculating time and shit\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "# To import a behavior agents for controlling car\n",
    "from agents.navigation.basic_agent import BasicAgent\n",
    "from agents.navigation.behavior_agent import BehaviorAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the sim, create the world\n",
    "client = carla.Client('localhost', 2000)\n",
    "\n",
    "# the town we've been using is town04, feel free to load different towns, goes to 012 i believe\n",
    "client.load_world('Town04')\n",
    "\n",
    "#define environment/world and get possible places to spawn a car\n",
    "world = client.get_world()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "# function for clearing da world\n",
    "def clear_world():\n",
    "    # clears all vehicles + sensors and sets them to None\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "        actor = None\n",
    "    for sensor in world.get_actors().filter('*sensor*'):\n",
    "        sensor.destroy()\n",
    "        sensor = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicle setup\n",
    "\n",
    "# TODO: turn this into a Vehicle class, and create a TrafficManager class to handle the fleet\n",
    "# collision sensor setup (for dealing with crashes)\n",
    "def setup_collision_sensor(vehicle, callback):\n",
    "    # Get the blueprint for the collision sensor\n",
    "    blueprint_library = vehicle.get_world().get_blueprint_library()\n",
    "    collision_bp = blueprint_library.find('sensor.other.collision')\n",
    "\n",
    "    # Set the transform relative to the vehicle\n",
    "    transform = carla.Transform(carla.Location(x=1.5, z=2.4))  # Front of the vehicle\n",
    "\n",
    "    # Spawn the collision sensor and attach it to the vehicle\n",
    "    collision_sensor = vehicle.get_world().spawn_actor(collision_bp, transform, attach_to=vehicle)\n",
    "\n",
    "    # Listen for collision events\n",
    "    collision_sensor.listen(lambda event: callback(event))\n",
    "\n",
    "    return collision_sensor\n",
    "\n",
    "# function to spawn a vehicle. Will move simulator camera to car position as well.\n",
    "def spawn_vehicle(pointNumber=1):#look for a blueprint of Mini car\n",
    "    global start_point\n",
    "    vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "\n",
    "    #spawn a car in a random location\n",
    "    \n",
    "    start_point = spawn_points[pointNumber]\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "\n",
    "    # move simulator view to the car\n",
    "    spectator = world.get_spectator()\n",
    "    start_point.location.z = start_point.location.z+1 #start_point was used to spawn the car but we move 1m up to avoid being on the floor\n",
    "    spectator.set_transform(start_point)\n",
    "    return vehicle\n",
    "\n",
    "# sets up the cameras\n",
    "def setup_cameras(vehicle):\n",
    "    world = vehicle.get_world()\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    \n",
    "    # Semantic camera setup\n",
    "    camera_bp = blueprint_library.find('sensor.camera.semantic_segmentation')\n",
    "    camera_bp.set_attribute('image_size_x', '640')\n",
    "    camera_bp.set_attribute('image_size_y', '480')\n",
    "    camera_bp.set_attribute('fov', '90')\n",
    "    camera_sem = world.spawn_actor(\n",
    "        camera_bp,\n",
    "        carla.Transform(carla.Location(z=1.3, x=1.4)),\n",
    "        attach_to=vehicle\n",
    "    )\n",
    "    \n",
    "    # RGB camera setup\n",
    "    camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', '640')\n",
    "    camera_bp.set_attribute('image_size_y', '480')\n",
    "    camera_bp.set_attribute('fov', '90')\n",
    "    camera_rgb = world.spawn_actor(\n",
    "        camera_bp,\n",
    "        carla.Transform(carla.Location(z=1.3, x=1.4)),\n",
    "        attach_to=vehicle\n",
    "    )\n",
    "\n",
    "    # Callbacks for camera data\n",
    "    def sem_callback(image, data_dict):\n",
    "        image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "        data_dict['sem_image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    \n",
    "    def rgb_callback(image, data_dict):\n",
    "        data_dict['rgb_image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "    camera_data = {'sem_image': np.zeros((480, 640, 4)), 'rgb_image': np.zeros((480, 640, 4))}\n",
    "    \n",
    "    camera_sem.listen(lambda image: sem_callback(image, camera_data))\n",
    "    camera_rgb.listen(lambda image: rgb_callback(image, camera_data))\n",
    "    \n",
    "    return camera_sem, camera_rgb, camera_data\n",
    "\n",
    "def print_vehicle_controls(vehicle):\n",
    "    control = vehicle.get_control()\n",
    "    normalized_steer = (control.steer + 1) /2\n",
    "    normalized_throttle = (control.throttle)\n",
    "    normalized_brake = (control.brake)\n",
    "    print(\"Steer: {:.3f}, Throttle: {:.3f}, Brake: {:.3f}\".format(normalized_steer, normalized_throttle, normalized_brake))\n",
    "\n",
    "\n",
    "def setAgent(vehicle):\n",
    "\n",
    "    # start a basic agent for the car\n",
    "    agent = BasicAgent(vehicle)\n",
    "\n",
    "    # give it a normal profile\n",
    "    agent = BehaviorAgent(vehicle, behavior='normal') # maybe set to aggressive?\n",
    "\n",
    "    destination = spawn_points[0].location # for now we just take the second spawn point\n",
    "                                  # later use a CARLA location at self.x + 10 or something\n",
    "\n",
    "    agent.set_destination(destination)\n",
    "\n",
    "    #lights always on\n",
    "    vehicle.set_light_state(carla.VehicleLightState.LowBeam)\n",
    "    return agent\n",
    "\n",
    "\n",
    "def on_collision(event):\n",
    "    print(\"Collision detected: Actor %s hit %s\" % (event.other_actor.type_id, event.actor.type_id))\n",
    "    # Stop the vehicle (or apply any other logic you deem necessary)\n",
    "    respawn_car()\n",
    "    \n",
    "def respawn_car(spawnPoint=None):\n",
    "    global vehicle, agent, collision_sensor, camera_sem, camera_rgb, camera_data\n",
    "    # Destroy existing actors if they exist\n",
    "    \n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for sensor in world.get_actors().filter('*sensor*'):\n",
    "        sensor.destroy()\n",
    "    if vehicle is not None:\n",
    "        vehicle.destroy()\n",
    "        vehicle = None\n",
    "    if collision_sensor is not None:\n",
    "        collision_sensor.destroy()\n",
    "        collision_sensor = None\n",
    "    if camera_sem is not None:\n",
    "        camera_sem.destroy()\n",
    "        camera_sem = None\n",
    "    if camera_rgb is not None:\n",
    "        camera_rgb.destroy()\n",
    "        camera_rgb = None\n",
    "    \n",
    "    \n",
    "    # if spawnpoint is unspecified, spawn new vehicle at random place\n",
    "    \n",
    "    if (spawnPoint):\n",
    "        random_spawnpoint = spawnPoint\n",
    "    \n",
    "    print(\"Vehicle spawned at spawn point: \", random_spawnpoint)\n",
    "    random_spawnpoint = random.randint(0, 10)  # Both 1 and 10 are included\n",
    "    vehicle = spawn_vehicle(random_spawnpoint)\n",
    "    \n",
    "    # sometimes the vehicle isn't spawned correctly and \n",
    "    # other threads try to read it and then it gets fucked\n",
    "    if vehicle is None:\n",
    "        raise Exception(\"Failed to spawn vehicle\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    # delay for a second just in case\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Setup collision sensor\n",
    "    collision_sensor = setup_collision_sensor(vehicle, on_collision)\n",
    "\n",
    "    # Setup cameras\n",
    "    camera_sem, camera_rgb, camera_data = setup_cameras(vehicle)\n",
    "\n",
    "    # Setup or reset the agent\n",
    "    agent = setAgent(vehicle)\n",
    "\n",
    "    print(\"New vehicle and sensors spawned. Continuing simulation...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for the main loop\n",
    "\n",
    "def get_random_waypoint(world):\n",
    "    map = world.get_map()\n",
    "    # Generate waypoints every 2 meters\n",
    "    waypoints = map.generate_waypoints(distance=2.0)\n",
    "    return random.choice(waypoints)\n",
    "\n",
    "def distance(location1, location2):\n",
    "    return math.sqrt((location1.x - location2.x)**2 + (location1.y - location2.y)**2 + (location1.z - location2.z)**2)\n",
    "\n",
    "# returns the openCV objects of rgb/segmented images from CARLA\n",
    "def grab_pictures():\n",
    "#     print_vehicle_controls(vehicle)\n",
    "        \n",
    "#     steering_wheel_direction = control.steer\n",
    "    rgb_im = camera_data['rgb_image']\n",
    "    sem_im = camera_data['sem_image']\n",
    "\n",
    "    # display images\n",
    "    im_h = cv2.hconcat([rgb_im,sem_im])\n",
    "    cv2.imshow('2 cameras', im_h)\n",
    "    \n",
    "    return rgb_im, sem_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "New vehicle and sensors spawned. Continuing simulation...\n"
     ]
    }
   ],
   "source": [
    "# initialize global variables and create the car\n",
    "    \n",
    "vehicle = None\n",
    "agent = None\n",
    "collision_sensor = None\n",
    "camera_sem = None\n",
    "camera_rgb = None\n",
    "camera_data = None\n",
    "start_point = None\n",
    "\n",
    "respawn_car()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught RuntimeError while trying to control the vehicle: name 'control' is not defined\n",
      "Caught RuntimeError while trying to control the vehicle: name 'control' is not defined\n",
      "Caught RuntimeError while trying to control the vehicle: name 'control' is not defined\n",
      "Caught RuntimeError while trying to control the vehicle: name 'control' is not defined\n",
      "Caught RuntimeError while trying to control the vehicle: name 'control' is not defined\n",
      "Caught RuntimeError while trying to control the vehicle: name 'control' is not defined\n",
      "Caught RuntimeError while trying to control the vehicle: name 'control' is not defined\n",
      "Caught RuntimeError while trying to control the vehicle: name 'control' is not defined\n"
     ]
    }
   ],
   "source": [
    "# function to capture CARLA's segmented images.\n",
    "# as of now, ./out_sem/rgb and ./out_sem/sem folder for it to export properly.\n",
    "\n",
    "\n",
    "# TODO: will refactor the code to make it object-oriented and implement thread locks\n",
    "last_capture_time = time.time()\n",
    "interval = 7.5 # set interval to 10 seconds\n",
    "sharp_steer_interval = 0.1\n",
    "light_steer_interval = 0.75\n",
    "\n",
    "\n",
    "    \n",
    "current_waypoint = None\n",
    "\n",
    "if vehicle is None:\n",
    "    respawn_car()\n",
    "while True:\n",
    "    \n",
    "    # advance the world\n",
    "    world.tick()\n",
    "\n",
    "    if vehicle is not None and agent is not None:\n",
    "        try:\n",
    "            control = agent.run_step()\n",
    "\n",
    "            vehicle.apply_control(control)\n",
    "            current_time = time.time()\n",
    "            control = vehicle.get_control()\n",
    "\n",
    "            # note try to factor this out later lol\n",
    "            # on light turn, delay 0.5\n",
    "            if abs(control.steer * 100) >= 5 and abs(control.steer * 100) < 10:\n",
    "\n",
    "\n",
    "                if current_time - last_capture_time >= light_steer_interval:\n",
    "                    rgb_im, sem_im = grab_pictures()\n",
    "                    # grab the time\n",
    "                    time_grab = time.time_ns()\n",
    "                    # normalize controls to between 0 and 100, with 50 being straight or nothing\n",
    "                    normalized_steer = (control.steer + 1) /2\n",
    "                    normalized_throttle = (control.throttle)\n",
    "                    normalized_brake = (control.brake)\n",
    "                    cv2.imwrite('out_sem/rgb/%06d_%.3f_%.3f_%.3f.png' % (time_grab, normalized_steer, normalized_throttle, normalized_brake), rgb_im)\n",
    "                    cv2.imwrite('out_sem/sem/%06d_%.3f_%.3f_%.3f.png' % (time_grab, normalized_steer, normalized_throttle, normalized_brake), sem_im)\n",
    "                    last_capture_time = current_time  # Update time\n",
    "\n",
    "            # on sharp turn, delay 0.1\n",
    "            elif abs(control.steer * 100) >= 10:\n",
    "                if current_time - last_capture_time >= sharp_steer_interval:\n",
    "                    # normalize controls to between 0 and 100, with 50 being straight or nothing\n",
    "                    rgb_im, sem_im = grab_pictures()\n",
    "                    # grab the time\n",
    "                    time_grab = time.time_ns()\n",
    "                    normalized_steer = (control.steer + 1) /2\n",
    "                    normalized_throttle = (control.throttle)\n",
    "                    normalized_brake = (control.brake)\n",
    "                    cv2.imwrite('out_sem/rgb/%06d_%.3f_%.3f_%.3f.png' % (time_grab, normalized_steer, normalized_throttle, normalized_brake), rgb_im)\n",
    "                    cv2.imwrite('out_sem/sem/%06d_%.3f_%.3f_%.3f.png' % (time_grab, normalized_steer, normalized_throttle, normalized_brake), sem_im)\n",
    "                    last_capture_time = current_time  # Update time\n",
    "\n",
    "\n",
    "            elif current_time - last_capture_time >= interval:        \n",
    "                rgb_im, sem_im = grab_pictures()\n",
    "\n",
    "                time_grab = time.time_ns()\n",
    "\n",
    "                normalized_steer = (control.steer + 1) /2\n",
    "                normalized_throttle = (control.throttle)\n",
    "                normalized_brake = (control.brake)\n",
    "                cv2.imwrite('out_sem/rgb/%06d_%.3f_%.3f_%.3f.png' % (time_grab, normalized_steer, normalized_throttle, normalized_brake), rgb_im)\n",
    "                cv2.imwrite('out_sem/sem/%06d_%.3f_%.3f_%.3f.png' % (time_grab, normalized_steer, normalized_throttle, normalized_brake), sem_im)        \n",
    "                # update time\n",
    "                last_capture_time = current_time\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "            if agent.done():\n",
    "                while True:\n",
    "                    new_waypoint = get_random_waypoint(world)\n",
    "                    if current_waypoint is None or distance(current_waypoint.transform.location, new_waypoint.transform.location) > 50:  # Check if new waypoint is at least 50 meters away\n",
    "                        break\n",
    "                print(\"reached waypoint, heading to: \", new_waypoint) \n",
    "                agent.set_destination(new_waypoint.transform.location)\n",
    "                current_waypoint = new_waypoint\n",
    "        except Exception as e:\n",
    "            print(\"Caught RuntimeError while trying to control the vehicle:\", e)\n",
    "            time.sleep(1)\n",
    "    \n",
    "\n",
    "clear_world()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Clarence\\\\Documents\\\\Coding\\\\cs141\\\\researchProject\\\\selfDrivingCar\\\\Self_Driving_Car\\\\models\\\\driver_model-3.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21008\\2099335444.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpredict_control\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# if vehicle is None:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrespawn_car\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Coding\\cs141\\researchProject\\selfDrivingCar\\Self_Driving_Car\\Driving\\predict_control.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Load trained model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Load trained model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\carla-sim\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\carla-sim\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\carla-sim\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Clarence\\\\Documents\\\\Coding\\\\cs141\\\\researchProject\\\\selfDrivingCar\\\\Self_Driving_Car\\\\models\\\\driver_model-3.pt'"
     ]
    }
   ],
   "source": [
    "from predict_control import predict\n",
    "\n",
    "\n",
    "# if vehicle is None:\n",
    "respawn_car()\n",
    "    \n",
    "# see if you can keep a '3 second log' and then write to it when you crash\n",
    "while True:\n",
    "    \n",
    "    world.tick()\n",
    "    try:\n",
    "        rgb_im, sem_im = grab_pictures()\n",
    "\n",
    "        prediction = predict(sem_im, CARLA=True)\n",
    "\n",
    "        new_steering = 2 * (prediction[0] - 0.5)\n",
    "        print(f\"steer: {new_steering}, throttle: {prediction[1]}, brake: {prediction[2]}\")\n",
    "        control = carla.VehicleControl(steer=new_steering, throttle=prediction[1], brake=0.0)\n",
    "        vehicle.apply_control(control)\n",
    "        current_time = time.time()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        time.sleep(1)\n",
    "        respawn_car()\n",
    "#     control = vehicle.get_control()\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "clear_world()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab a snapshot from the camera an show in a pop-up window\n",
    "img = camera_data['image']\n",
    "cv2.imshow('RGB Camera',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up after yourself\n",
    "\n",
    "# camera.stop() # this is the opposite of camera.listen\n",
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "    actor.destroy()\n",
    "for sensor in world.get_actors().filter('*sensor*'):\n",
    "    sensor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10422"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spawn_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_point = spawn_points[0]\n",
    "spectator = world.get_spectator()\n",
    "spectator.set_transform(start_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectator.set_transform(carla.Transform(carla.Location(x=-1085.286377, y=3112.225830, z=356.060608), carla.Rotation(pitch=1.648070, yaw=20.234367, roll=0.000000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform(Location(x=-1085.286377, y=3112.225830, z=356.060608), Rotation(pitch=1.648070, yaw=20.234367, roll=0.000000))\n"
     ]
    }
   ],
   "source": [
    "print(start_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
